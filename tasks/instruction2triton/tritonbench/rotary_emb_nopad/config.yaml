compile_command:
- python rotary_emb_nopad.py
correctness_command:
- python rotary_emb_nopad_perf.py
performance_command:
- tb_eval -f rotary_emb_nopad.py -o rotary_emb_nopad_output.json -run_on_code -ds
  tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \        The Triton kernel code implements the `rotary_embedding` function, which\
    \ provides rotary positional embeddings for transformer architectures. It operates\
    \ in two modes based on the presence of `k_cache`. The `rotary_embedding_kernel`\
    \ is invoked when `k_cache` is None and processes the query (`q`) and key (`k`)\
    \ tensors by loading precomputed cosine (`cos`) and sine (`sin`) values according\
    \ to their strides and positions. It then applies these trigonometric values to\
    \ the tensors to perform a rotation operation defined as: out_q0 = loaded_q0 *\
    \ loaded_cos - loaded_q1 * loaded_sin and out_q1 = loaded_q0 * loaded_sin + loaded_q1\
    \ * loaded_cos for the queries and similarly for the keys if applicable. The `fused_rotary_embedding_kernel_v2`\
    \ handles the case when `k_cache` is provided. This involves using block-wise\
    \ operations for cache management. For this, it utilizes additional input tensors\
    \ like `block_tables` to determine storage positions within the cache and `kv_lengths`\
    \ for past sequence length information. Both kernels leverage trigonometric identities\
    \ to rotate the embeddings and conditionally store results based on the compute\
    \ strategy defined by `grid` settings which scale based on input tensor dimensions\
    \ and number of threads (`num_warps`). Essential inputs include `q`, `k`, `cos`,\
    \ `sin`, and optionally `k_cache`, `block_tables`, and `kv_lengths`. Important\
    \ constants like `Q_HEAD_NUM` and `HEAD_DIM` are used to define structural properties\
    \ of the input tensors.\n    \nThe test code is:\n\n\ndef test_rotary_embedding():\n\
    \    # \u6D4B\u8BD5\u53C2\u6570\n    total_tokens = 32  # \u603B token \u6570\n\
    \    head_num = 8       # Query \u7684\u5934\u6570\u91CF\n    kv_head_num = 4\
    \    # Key/Value \u7684\u5934\u6570\u91CF\n    head_dim = 64      # \u6BCF\u4E2A\
    \u5934\u7684\u7EF4\u5EA6\n    max_position_len = 128  # \u6700\u5927\u4F4D\u7F6E\
    \u957F\u5EA6\n    block_size = 4     # \u5757\u5927\u5C0F\n\n    # \u521B\u5EFA\
    \u8F93\u5165\u5F20\u91CF\n    q = torch.randn((total_tokens, head_num, head_dim),\
    \ dtype=torch.float32, device='cuda')  # Query\n    k = torch.randn((total_tokens,\
    \ kv_head_num, head_dim), dtype=torch.float32, device='cuda')  # Key\n    cos\
    \ = torch.randn((max_position_len, head_dim), dtype=torch.float32, device='cuda')\
    \  # Cosine\n    sin = torch.randn((max_position_len, head_dim), dtype=torch.float32,\
    \ device='cuda')  # Sine\n\n    result = {}\n\n    # \u8C03\u7528 rotary_embedding\
    \ \u5206\u652F 1 (\u4E0D\u4F7F\u7528 k_cache)\n    rotary_embedding(q, k, cos,\
    \ sin)\n    result[\"test_case_1\"] = (q.clone(), k.clone())\n\n    # \u521B\u5EFA\
    \u9644\u52A0\u5F20\u91CF\u7528\u4E8E\u5206\u652F 2\n    num_blocks = 4  # Number\
    \ of blocks in k_cache\n    batch_size = 2  # Batch size\n    k_cache = torch.randn((num_blocks,\
    \ kv_head_num, block_size, head_dim), dtype=torch.float32, device='cuda')  # Key\
    \ cache\n    block_tables = torch.randint(0, num_blocks, (batch_size, num_blocks),\
    \ device='cuda')  # Block tables\n    kv_lengths = torch.randint(1, total_tokens,\
    \ (batch_size,), device='cuda')  # KV lengths\n\n    # \u8C03\u7528 rotary_embedding\
    \ \u5206\u652F 2 (\u4F7F\u7528 k_cache)\n    rotary_embedding(q, k, cos, sin,\
    \ k_cache=k_cache, block_tables=block_tables, kv_lengths=kv_lengths)\n    result[\"\
    test_case_2\"] = (q.clone(), k.clone(), k_cache.clone())\n\n    return result\n\
    \nresult_gold = test_rotary_embedding()\n\n\nDon't append test code to the kernel\
    \ code or edit test function.\n\nThe generated code should be written into a python\
    \ file.\nIf you have already created a file and wrote the code into it, edit the\
    \ code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ rotary_emb_nopad.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- rotary_emb_nopad
