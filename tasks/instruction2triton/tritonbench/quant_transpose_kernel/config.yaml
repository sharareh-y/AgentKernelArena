compile_command:
- python quant_transpose_kernel.py
correctness_command:
- python quant_transpose_kernel_perf.py
performance_command:
- tb_eval -f quant_transpose_kernel.py -o quant_transpose_kernel_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton function `_quantize_global_transpose` performs a global\
    \ quantization and transposition of a matrix `A`. It operates on a block of size\
    \ `BLOCK_M` by `BLOCK_N` and partitions the matrix into groups as determined by\
    \ `GROUP_M`. The kernel computes the grid dimensions needed to cover the matrix\
    \ based on `M` and `N`, which represent the dimensions of `A`. The `program_id`\
    \ is split into group indices `pid_m` and `pid_n` to navigate over blocks. `A`\
    \ is accessed using pointers adjusted with `stride_am` and `stride_an`, and the\
    \ quantization is achieved by multiplying each element by `absmax_inv` and scaling\
    \ to int8 range. The result is stored in matrix `B`, transposing the indices using\
    \ `stride_bm` and `stride_bn`. The `quantize_global_transpose` function facilitates\
    \ the kernel launch, preparing the input by calculating `absmax` and its reciprocal,\
    \ then initializes the output matrix. It defines a lambda to configure the launch\
    \ grid based on the matrix dimensions and block sizes.\n            \nThe test\
    \ code is:\n\n\nimport torch\n\n# Test for quantize_global_transpose\ndef test_quantize_global_transpose():\n\
    \    results = {}\n    \n    # Create a random 2D tensor on CUDA for first test\
    \ case\n    input_tensor_1 = torch.randn(128, 256, device='cuda', dtype=torch.float32)\n\
    \    # Call the quantize_global_transpose function for the first test case\n \
    \   output_1, absmax_1 = quantize_global_transpose(input_tensor_1)\n    results[\"\
    test_case_1\"] = (output_1, absmax_1)\n\n    # Create a random 2D tensor on CUDA\
    \ for second test case\n    input_tensor_2 = torch.randn(256, 128, device='cuda',\
    \ dtype=torch.float32)\n    # Call the quantize_global_transpose function for\
    \ the second test case\n    output_2, absmax_2 = quantize_global_transpose(input_tensor_2)\n\
    \    results[\"test_case_2\"] = (output_2, absmax_2)\n\n    # Create a random\
    \ 2D tensor on CUDA for third test case\n    input_tensor_3 = torch.randn(512,\
    \ 256, device='cuda', dtype=torch.float32)\n    # Call the quantize_global_transpose\
    \ function for the third test case\n    output_3, absmax_3 = quantize_global_transpose(input_tensor_3)\n\
    \    results[\"test_case_3\"] = (output_3, absmax_3)\n\n    # Create a random\
    \ 2D tensor on CUDA for fourth test case\n    input_tensor_4 = torch.randn(256,\
    \ 512, device='cuda', dtype=torch.float32)\n    # Call the quantize_global_transpose\
    \ function for the fourth test case\n    output_4, absmax_4 = quantize_global_transpose(input_tensor_4)\n\
    \    results[\"test_case_4\"] = (output_4, absmax_4)\n    \n    return results\n\
    \nresult_gold = test_quantize_global_transpose()\n\n\nDon't append test code to\
    \ the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ quant_transpose_kernel.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- quant_transpose_kernel
