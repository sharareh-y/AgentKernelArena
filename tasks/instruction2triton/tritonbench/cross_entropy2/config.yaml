compile_command:
- python cross_entropy2.py
correctness_command:
- python cross_entropy2_perf.py
performance_command:
- tb_eval -f cross_entropy2.py -o cross_entropy2_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \    This Triton implementation provides a mechanism to calculate cross-entropy\
    \ loss and its gradients efficiently using GPU parallelism. It involves two main\
    \ kernels: `cross_entropy_fwd_kernel` for the forward pass and `cross_entropy_bwd_kernel`\
    \ for the backward pass.\n\n    The `cross_entropy_fwd_kernel` is executed for\
    \ each row (determined by `tl.program_id(0)`) and for each block of columns within\
    \ that row (determined by `tl.program_id(1)`). The kernel computes the logits\
    \ for each block, applies logit scaling, and calculates the log-sum-exp (lse).\
    \ It also handles scenarios with label smoothing, optionally computes a scaled\
    \ squared value of the lse (z_loss), and stores both the loss and z_loss in the\
    \ provided pointers.\n\n    Specific checks are included for whether the label\
    \ at the current index matches an `ignored_index`, which sets the loss and z_loss\
    \ to zero if true. Moreover, conditional compilation flags like `HAS_SMOOTHING`\
    \ and `SPLIT` enable or disable features such as smoothing and splitting the loss\
    \ computation.\n\n    The `cross_entropy_bwd_kernel` computes the gradient of\
    \ the loss with respect to the logits (dlogits). It calculates probabilities from\
    \ the logits and adjusts them based on the lse. Depending on whether label smoothing\
    \ is enabled, it modifies the gradients accordingly and stores them. The grid\
    \ configuration uses row index and block index to partition the computation efficiently.\n\
    \n    The wrapper functions, `cross_entropy_fwd` and `cross_entropy_bwd`, prepare\
    \ and dispatch these kernels with the specified grid dimensions based on the input\
    \ tensor shapes. They also print intermediate results such as `loss`, `lse`, `z_loss`,\
    \ and `dlogits` for debugging purposes.\n\n    Parameters:\n    - logits: Input\
    \ tensor containing the logit values.\n    - labels: Tensor with the target class\
    \ labels.\n    - smoothing, logit_scale, lse_square_scale: Scalars adjusting the\
    \ loss computation.\n    - ignored_index: Specifies any label to ignore.\n   \
    \ - total_classes, class_start_idx: Help manage subsetting classes in parallel\
    \ scenarios.\n    - BLOCK_SIZE: Constant specifying the number of columns processed\
    \ in parallel.\n    - HAS_SMOOTHING, SPLIT: Boolean flags for feature toggling.\n\
    \n    Outputs:\n    - Forward pass: Returns tensors for `loss`, `lse`, and `z_loss`.\n\
    \    - Backward pass: Returns tensor `dlogits` containing gradients of the logits.\n\
    \    \nThe test code is:\n\n\nimport torch\n\ndef test_cross_entropy_kernels():\n\
    \    # Test parameters\n    n_rows = 4  # Number of rows (batch size)\n    n_cols\
    \ = 8  # Number of columns (number of classes)\n    BLOCK_SIZE = 4  # Block size\
    \ for kernel\n    smoothing = 0.1  # Label smoothing factor\n    logit_scale =\
    \ 1.0  # Scale for logits\n    lse_square_scale = 0.1  # Scaling for LSE square\
    \ loss\n    ignored_index = -1  # Index to ignore in labels\n    total_classes\
    \ = 10  # Total number of classes\n    class_start_idx = 0  # Start index for\
    \ class partitioning\n\n    # Test data\n    logits = torch.randn((n_rows, n_cols),\
    \ dtype=torch.float32, device='cuda')\n    labels = torch.randint(0, n_cols, (n_rows,),\
    \ dtype=torch.int32, device='cuda')\n    dloss = torch.randn((n_rows,), dtype=torch.float32,\
    \ device='cuda')\n\n    results = {}\n\n    # Test without smoothing and without\
    \ split\n    loss, lse, z_loss = cross_entropy_fwd(logits, labels, 0.0, logit_scale,\
    \ lse_square_scale, ignored_index, total_classes, class_start_idx, BLOCK_SIZE,\
    \ False, False)\n    dlogits = cross_entropy_bwd(dloss, logits, lse, labels, 0.0,\
    \ logit_scale, lse_square_scale, ignored_index, total_classes, class_start_idx,\
    \ BLOCK_SIZE, False)\n    results['test_case_1'] = (loss, lse, z_loss, dlogits)\n\
    \n    # Test with smoothing and without split\n    loss, lse, z_loss = cross_entropy_fwd(logits,\
    \ labels, smoothing, logit_scale, lse_square_scale, ignored_index, total_classes,\
    \ class_start_idx, BLOCK_SIZE, True, False)\n    dlogits = cross_entropy_bwd(dloss,\
    \ logits, lse, labels, smoothing, logit_scale, lse_square_scale, ignored_index,\
    \ total_classes, class_start_idx, BLOCK_SIZE, True)\n    results['test_case_2']\
    \ = (loss, lse, z_loss, dlogits)\n\n    # Test with smoothing and with split\n\
    \    loss, lse, z_loss = cross_entropy_fwd(logits, labels, smoothing, logit_scale,\
    \ lse_square_scale, ignored_index, total_classes, class_start_idx, BLOCK_SIZE,\
    \ True, True)\n    dlogits = cross_entropy_bwd(dloss, logits, lse, labels, smoothing,\
    \ logit_scale, lse_square_scale, ignored_index, total_classes, class_start_idx,\
    \ BLOCK_SIZE, True)\n    results['test_case_3'] = (loss, lse, z_loss, dlogits)\n\
    \n    return results\n\n# Run the test cases\nresult_gold = test_cross_entropy_kernels()\n\
    # \u5206\u652F\u8986\u76D6\u7387\u4E3A\u30103/4\u3011\n\n\nDon't append test code\
    \ to the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ cross_entropy2.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- cross_entropy2
