compile_command:
- python matrix_transpose.py
correctness_command:
- python matrix_transpose_perf.py
performance_command:
- tb_eval -f matrix_transpose.py -o matrix_transpose_output.json -run_on_code -ds
  tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    The Triton operator is defined to transpose a matrix using a kernel function and\
    \ a wrapper function. The kernel function named 'kernel' is decorated with '@triton.jit'\
    \ for just-in-time compilation and performs matrix transposition by directly manipulating\
    \ pointers based on the given strides and dimensions. It accepts input parameters\
    \ such as a matrix 'M', an output buffer 'Out', the strides of 'M' and 'Out',\
    \ and the dimensions 'SIZE_M' and 'D_HEAD'. The kernel computes the pointers for\
    \ elements of 'M' using 'matrix_stridex' and 'matrix_stridey', and for 'Out' using\
    \ 'out_stridex' and 'out_stridey'. The transposition is achieved by loading elements\
    \ from 'M' and storing them into 'Out' in a transposed layout. The wrapper function\
    \ named 'wrapper' initializes 'matrix' with random float16 values and 'out' with\
    \ zeros, both on CUDA. It defines the grid configuration as a tuple with a single\
    \ element, then calls the kernel with these matrices and their properties. Finally,\
    \ it returns the transposed matrix 'out'.\n    \nThe test code is:\n\n\nimport\
    \ torch\n\ndef test_triton_vs_torch():\n    results = {}\n\n    # \u6D4B\u8BD5\
    \u7528\u4F8B 1: \u57FA\u672C\u77E9\u9635\u8F6C\u7F6E (\u5C0F\u77E9\u9635)\n  \
    \  size_m, d_head = 16, 16\n    out = wrapper(size_m, d_head)\n    results[\"\
    test_case_1\"] = out.clone()\n\n    # \u6D4B\u8BD5\u7528\u4F8B 2: \u975E\u65B9\
    \u5F62\u77E9\u9635\n    size_m, d_head = 32, 64\n    out = wrapper(size_m, d_head)\n\
    \    results[\"test_case_2\"] = out.clone()\n\n    return results\n\n\n# \u8FD0\
    \u884C\u6D4B\u8BD5\nresult_gold = test_triton_vs_torch()\n# print(result_gold)\n\
    \nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py matrix_transpose.py {kernel_path}`\
    \ to check the correctness and performance.The kernel_path is where you stored\
    \ the generated code.\nCall Status means whether the code can be executed, Exec\
    \ Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- matrix_transpose
