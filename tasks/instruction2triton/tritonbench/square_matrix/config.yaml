compile_command:
- python square_matrix.py
correctness_command:
- python square_matrix_perf.py
performance_command:
- tb_eval -f square_matrix.py -o square_matrix_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \    This Triton kernel `square_kernel` computes the element-wise square of each\
    \ element in a 2D input tensor. The kernel logic works as follows:\n    - It launches\
    \ one instance per row of the input, making rows independent for parallel execution.\
    \ \n    - The function parameters include pointers to the input and output, the\
    \ row strides for input and output, the number of columns, and the `BLOCK_SIZE`\
    \ representing the power of two greater than the number of columns to manage the\
    \ memory layout.\n    - For each row, it calculates starting pointers and loads\
    \ the row into SRAM using `tl.load` with a masking operation to handle cases where\
    \ `BLOCK_SIZE` exceeds the number of columns.\n    - The computation of squaring\
    \ each element in the row is performed simply by multiplying the row with itself,\
    \ stored in `square_output`.\n    - Finally, it stores the squared values back\
    \ to global memory using `tl.store`.\n\n    The wrapper function `square`:\n \
    \   - Accepts a 2D tensor `x` and computes the number of rows and columns.\n \
    \   - Determines `BLOCK_SIZE` as the smallest power of two greater than `n_cols`\
    \ and sets `num_warps` for parallel execution; it adjusts this based on `BLOCK_SIZE`\
    \ to optimize performance.\n    - Allocates an output tensor `y` using PyTorch's\
    \ `empty_like` to match the input tensor's shape.\n    - Launches the `square_kernel`\
    \ with a 1D grid configuration corresponding to the number of rows, ensuring each\
    \ row is processed by one kernel instance.\n    - Returns the squared tensor `y`.\n\
    \    \nThe test code is:\n\n\nimport torch\n\ndef test_square():\n    x_triton_1\
    \ = torch.randn(128, 64, device='cuda')\n    x_triton_2 = torch.randn(128, 128,\
    \ device='cuda')\n    x_triton_3 = torch.randn(128, 256, device='cuda')\n    x_triton_4\
    \ = torch.randn(128, 512, device='cuda')\n\n    y_triton_1 = square(x_triton_1)\n\
    \    y_triton_2 = square(x_triton_2)\n    y_triton_3 = square(x_triton_3)\n  \
    \  y_triton_4 = square(x_triton_4)\n\n    return {\n        \"test_case_1\": y_triton_1,\n\
    \        \"test_case_2\": y_triton_2,\n        \"test_case_3\": y_triton_3,\n\
    \        \"test_case_4\": y_triton_4\n    }\n\nresult_gold = test_square()\n\n\
    \nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py square_matrix.py {kernel_path}`\
    \ to check the correctness and performance.The kernel_path is where you stored\
    \ the generated code.\nCall Status means whether the code can be executed, Exec\
    \ Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- square_matrix
