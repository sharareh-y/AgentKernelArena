compile_command:
- python quantize_kv_transform.py
correctness_command:
- python quantize_kv_transform_perf.py
performance_command:
- tb_eval -f quantize_kv_transform.py -o quantize_kv_transform_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton kernel '_fwd_kernel_destindex_copy_quantize_kv' takes\
    \ input tensors 'K' and 'Dest_loc', along with output tensors 'Out' and 'Out_scale'.\
    \ It processes elements in blocks defined by 'BLOCK_HEAD' and 'BLOCK_DMODEL' which\
    \ are powers of two based on dimensions of 'K'. The kernel computes per-block\
    \ maximum absolute values to determine scales for quantization, scales the input\
    \ data, converts it to int8, and stores both the quantized data and corresponding\
    \ scales to the output tensors. Indices from 'Dest_loc' determine positions in\
    \ the output where processed blocks are stored. The 'destindex_copy_quantize_kv'\
    \ function is a no-gradient PyTorch wrapper that calls the Triton kernel, initializing\
    \ execution parameters such as grid size from 'seq_len', determining block sizes,\
    \ and specifying constraints on warps and stages.\n            \nThe test code\
    \ is:\n\n\ndef test_destindex_copy_quantize_kv():\n    B, N_CTX, H, D = 32, 1024,\
    \ 12, 96\n    src = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda()\n\
    \    dest_loc = torch.arange(0, B * N_CTX, dtype=torch.int32).cuda()\n    value_dest\
    \ = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda().to(torch.int8)\n\
    \    scale_dest = torch.randn((B * N_CTX, H, 1), dtype=torch.float16).cuda()\n\
    \n    # Test case 1\n    destindex_copy_quantize_kv(src, dest_loc, value_dest,\
    \ scale_dest)\n    result_1 = {\n        \"value_dest\": value_dest.clone(),\n\
    \        \"scale_dest\": scale_dest.clone()\n    }\n\n    # Test case 2: Different\
    \ dimensions\n    B, N_CTX, H, D = 16, 512, 8, 64\n    src = torch.randn((B *\
    \ N_CTX, H, D), dtype=torch.float16).cuda()\n    dest_loc = torch.arange(0, B\
    \ * N_CTX, dtype=torch.int32).cuda()\n    value_dest = torch.randn((B * N_CTX,\
    \ H, D), dtype=torch.float16).cuda().to(torch.int8)\n    scale_dest = torch.randn((B\
    \ * N_CTX, H, 1), dtype=torch.float16).cuda()\n    destindex_copy_quantize_kv(src,\
    \ dest_loc, value_dest, scale_dest)\n    result_2 = {\n        \"value_dest\"\
    : value_dest.clone(),\n        \"scale_dest\": scale_dest.clone()\n    }\n\n \
    \   # Test case 3: Different data types\n    src = torch.randn((B * N_CTX, H,\
    \ D), dtype=torch.float32).cuda()\n    destindex_copy_quantize_kv(src, dest_loc,\
    \ value_dest, scale_dest)\n    result_3 = {\n        \"value_dest\": value_dest.clone(),\n\
    \        \"scale_dest\": scale_dest.clone()\n    }\n\n    # Test case 4: Edge\
    \ case with minimal dimensions\n    B, N_CTX, H, D = 1, 1, 1, 1\n    src = torch.randn((B\
    \ * N_CTX, H, D), dtype=torch.float16).cuda()\n    dest_loc = torch.arange(0,\
    \ B * N_CTX, dtype=torch.int32).cuda()\n    value_dest = torch.randn((B * N_CTX,\
    \ H, D), dtype=torch.float16).cuda().to(torch.int8)\n    scale_dest = torch.randn((B\
    \ * N_CTX, H, 1), dtype=torch.float16).cuda()\n    destindex_copy_quantize_kv(src,\
    \ dest_loc, value_dest, scale_dest)\n    result_4 = {\n        \"value_dest\"\
    : value_dest.clone(),\n        \"scale_dest\": scale_dest.clone()\n    }\n\n \
    \   return {\n        \"test_case_1\": result_1,\n        \"test_case_2\": result_2,\n\
    \        \"test_case_3\": result_3,\n        \"test_case_4\": result_4\n    }\n\
    \nresult_gold = test_destindex_copy_quantize_kv()\n\n\nDon't append test code\
    \ to the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ quantize_kv_transform.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- quantize_kv_transform
