compile_command:
- python l2_norm_triton1.py
correctness_command:
- python l2_norm_triton1_perf.py
performance_command:
- tb_eval -f l2_norm_triton1.py -o l2_norm_triton1_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton kernel `_l2_norm_fwd_1pass_kernel` aims to perform L2\
    \ normalization on a 2D input tensor `X`. It processes each row separately using\
    \ Triton's parallel execution model. The kernel expects pointers to `X` and `Y`\
    \ along with the stride for rows (`stride_x_row`), number of columns in `X` (`N`),\
    \ a small constant `eps` to prevent division by zero, and a compile-time constant\
    \ `BLOCK_N`. The kernel computes L2 normalization by first loading a block of\
    \ data from `X`, calculating the sum of squares for variance, and computing the\
    \ reciprocal of the square root of the variance plus `eps` to get `rstd`. It then\
    \ multiplies the input block by `rstd` to produce the normalized values, which\
    \ are stored in `Y`.\n\n            The Python function `_l2_norm_fwd` handles\
    \ the setup and execution of the kernel. It first reshapes and possibly makes\
    \ the input tensor `x` contiguous. It initializes an empty tensor `y` to store\
    \ the output. The function calculates `BLOCK_N` based on `x`'s element size and\
    \ ensures it doesn't exceed 64KB. If the feature dimension `N` is larger than\
    \ `BLOCK_N`, it raises an error. The kernel is then launched with the total number\
    \ of rows `M`, pointers to `x` and `y`, stride, number of columns, `eps`, and\
    \ `BLOCK_N`. Finally, the function returns the normalized tensor reshaped to its\
    \ original dimensions.\n            \nThe test code is:\n\n\nimport torch\n\n\
    # Test the forward L2 normalization\ndef test_l2_norm_fwd():\n    results = {}\n\
    \    \n    # Test case 1\n    x1 = torch.randn(4, 8, device='cuda', dtype=torch.float32)\n\
    \    y1 = _l2_norm_fwd(x1)\n    results['test_case_1'] = y1\n\n    # Test case\
    \ 2: Different batch size\n    x2 = torch.randn(2, 8, device='cuda', dtype=torch.float32)\n\
    \    y2 = _l2_norm_fwd(x2)\n    results['test_case_2'] = y2\n\n    # Test case\
    \ 3: Different feature size\n    x3 = torch.randn(4, 4, device='cuda', dtype=torch.float32)\n\
    \    y3 = _l2_norm_fwd(x3)\n    results['test_case_3'] = y3\n\n    # Test case\
    \ 4: Larger tensor\n    x4 = torch.randn(8, 8, device='cuda', dtype=torch.float32)\n\
    \    y4 = _l2_norm_fwd(x4)\n    results['test_case_4'] = y4\n\n    return results\n\
    \nresult_gold = test_l2_norm_fwd()\n\n\nDon't append test code to the kernel code\
    \ or edit test function.\n\nThe generated code should be written into a python\
    \ file.\nIf you have already created a file and wrote the code into it, edit the\
    \ code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ l2_norm_triton1.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- l2_norm_triton1
