compile_command:
- python fast_layernorm.py
correctness_command:
- python fast_layernorm_perf.py
performance_command:
- tb_eval -f fast_layernorm.py -o fast_layernorm_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \    This code defines a custom layer normalization operation using Triton, a\
    \ library designed for writing high-performance custom GPU kernels. The `calculate_settings`\
    \ function computes the optimal block size and number of warps for a given number\
    \ of columns `n`. It ensures the block size does not exceed the maximum allowed\
    \ size (`MAX_FUSED_SIZE`). The `layernorm_forward` function is a JIT-compiled\
    \ kernel for computing the forward pass of layer normalization. It calculates\
    \ the mean and variance of each row of the input `X`, applies normalization using\
    \ these statistics, and scales/shifts the result with learned parameters `W` and\
    \ `b`. The `layernorm_backward` function computes the gradients of the input with\
    \ respect to the output loss gradient `dY`, using stored intermediate results\
    \ (`r`, `mu`) from the forward pass. `Fast_Layernorm` class is a PyTorch `autograd.Function`\
    \ implementing this custom layer normalization. The `forward` method sets up the\
    \ computation and calls `layernorm_forward`, while `backward` calls `layernorm_backward`\
    \ to compute the gradient of `X` with respect to `dY`. The `fast_layernorm` function\
    \ applies this custom layer normalization by interfacing with PyTorch's `nn.LayerNorm`\
    \ parameters, ensuring that the operation is done with `W` and `b` derived from\
    \ the PyTorch module.\n    \nThe test code is:\n\n\nimport torch\nimport torch.nn\
    \ as nn\n\ndef test_fast_layernorm_with_backward():\n    # Set the parameters\
    \ for the layer normalization\n    batch_size = 4\n    feature_size = 8\n    eps\
    \ = 1e-5\n\n    # Create a random input tensor with gradient tracking enabled\n\
    \    X = torch.randn(batch_size, feature_size, device='cuda:0', dtype=torch.float32,\
    \ requires_grad=True)\n\n    # Create a PyTorch LayerNorm module\n    layernorm\
    \ = nn.LayerNorm(feature_size, eps=eps, elementwise_affine=True).cuda()\n\n  \
    \  # Perform layer normalization using the fast_layernorm function\n    Y = fast_layernorm(layernorm,\
    \ X)\n\n    # Compute a dummy loss (e.g., mean of the output)\n    loss = Y.mean()\n\
    \n    # Perform backward propagation\n    loss.backward()\n\n    # Check the results\
    \ for the single branch tested\n    results = {\"test_case_1\": X.grad.clone()}\n\
    \n    return results\n\nresult_gold = test_fast_layernorm_with_backward()\n# Coverage:\
    \ [1/4]\n\n\nDon't append test code to the kernel code or edit test function.\n\
    \nThe generated code should be written into a python file.\nIf you have already\
    \ created a file and wrote the code into it, edit the code directly in the file.\n\
    Test the code by running `python python_bindings/tritonbench.py fast_layernorm.py\
    \ {kernel_path}` to check the correctness and performance.The kernel_path is where\
    \ you stored the generated code.\nCall Status means whether the code can be executed,\
    \ Exec Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- fast_layernorm
