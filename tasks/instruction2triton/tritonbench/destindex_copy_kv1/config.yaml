compile_command:
- python destindex_copy_kv1.py
correctness_command:
- python destindex_copy_kv1_perf.py
performance_command:
- tb_eval -f destindex_copy_kv1.py -o destindex_copy_kv1_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The code provides a Triton kernel named _fwd_kernel_destindex_copy_kv,\
    \ designed to facilitate the copying of tensor slices based on specified destination\
    \ indices. This kernel is invoked within the destindex_copy_kv function, a wrapper\
    \ function designed for PyTorch. The core functionality of the kernel involves\
    \ processing a 3D input tensor K, representing data across batch size, head number,\
    \ and head dimension, and transferring selected slices to the output tensor Out\
    \ using indices from the DestLoc tensor. Each element in DestLoc maps to a position\
    \ in the batch dimension of Out. The kernel logic iterates over each sequence\
    \ element, indexed by cur_index, and determines the corresponding slice to copy\
    \ using DestLoc. Offsets offs_h and offs_d calculate strides for accessing head\
    \ and depth dimensions. The kernel dynamically adapts to input sizes, employing\
    \ BLOCK_HEAD and BLOCK_DMODEL as block size parameters, computed as powers of\
    \ two for optimal performance. The wrapper function orchestrates kernel execution\
    \ by defining the execution grid as the sequence length, confirming dimensional\
    \ integrity between K and Out, and invoking the kernel with appropriate stride\
    \ and dimension parameters. By operating within Triton's just-in-time compilation\
    \ environment, this code exemplifies an efficient mechanism for parallel data\
    \ manipulation in deep learning models.\n            \nThe test code is:\n\n\n\
    import torch\n\ndef test_destindex_copy_kv():\n    B, N_CTX, H, D = 32, 1024,\
    \ 12, 96\n    dest = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda()\n\
    \    src = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda()\n    dest_loc\
    \ = torch.arange(0, B * N_CTX, dtype=torch.int32, device=\"cuda\")\n\n    destindex_copy_kv(src,\
    \ dest_loc, dest)\n    torch.cuda.synchronize()\n    test_case = torch.allclose(src,\
    \ dest, atol=1e-2, rtol=0)\n\n    return {\n        \"test_case\": test_case,\n\
    \    }\n\nresult_gold = test_destindex_copy_kv()\n\n\nDon't append test code to\
    \ the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ destindex_copy_kv1.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- destindex_copy_kv1
