compile_command:
- python destindex_copy_kv2.py
correctness_command:
- python destindex_copy_kv2_perf.py
performance_command:
- tb_eval -f destindex_copy_kv2.py -o destindex_copy_kv2_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The provided Triton kernel function `_fwd_kernel_destindex_copy_kv`\
    \ is a GPU-accelerated operation designed to perform indexed copying of tensor\
    \ data from `K` to `Out`, directed by indices specified in `Dest_loc`. The function\
    \ is invoked over a grid of size equal to `seq_len`, derived from the size of\
    \ `Dest_loc`. The main computation leverages Triton's parallel execution model\
    \ by determining the current index using `tl.program_id(0)`. It constructs pointers\
    \ for both source (`k_ptrs`) and destination (`o_ptrs`) using tensor strides for\
    \ batch size, head, and depth dimensions. The load operation is masked by `offs_h`\
    \ to ensure it stays within the valid `head_num` range. The wrapper function `destindex_copy_kv`\
    \ sets kernel parameters such as strides and grid configuration, validating that\
    \ the tensor shapes of `K` and `Out` align. It computes `BLOCK_HEAD` to be the\
    \ next power of 2 of `head_num` for performance optimization, using Triton's utility\
    \ function. The kernel is executed with a single warp, suitable for the problem\
    \ size, and encapsulates the entire logic for transferring indexed data based\
    \ on head and depth dimensions.\n            \nThe test code is:\n\n\ndef test_destindex_copy_kv():\n\
    \    B, N_CTX, H, D = 32, 1024, 12, 128\n    dest = torch.randn((B * N_CTX, H,\
    \ D), dtype=torch.float16).cuda()\n    src = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda()\n\
    \    dest_loc = torch.arange(0, B * N_CTX, dtype=torch.int32, device=\"cuda\"\
    )\n\n    destindex_copy_kv(src, dest_loc, dest)\n    test_case = torch.allclose(src,\
    \ dest, atol=1e-2, rtol=0)\n\n    return {\n        \"test_case_1\": test_case\n\
    \    }\n\nresult_gold = test_destindex_copy_kv()\n\nDon't append test code to\
    \ the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ destindex_copy_kv2.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- destindex_copy_kv2
