compile_command:
- python cache_transform_triton.py
correctness_command:
- python cache_transform_triton_perf.py
performance_command:
- tb_eval -f cache_transform_triton.py -o cache_transform_triton_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton code defines two GPU kernels using Triton's JIT compilation\
    \ to facilitate the manipulation of cosine and sine caches often employed in sequence-based\
    \ models.\n\n            - `prefill_cache_kernel`: This kernel is optimized for\
    \ pre-filling caches when given sequences (prompts) are involved. It receives\
    \ parameters like `cos_cache` and `sin_cache`, which are the source caches, and\
    \ target parameters like `cos_output` and `sin_output` for storing the processed\
    \ cache sections. The kernel calculates the original sequence index for each target\
    \ index using a cumulative sum of sequence lengths (`cumsum_lengths`) and extracts\
    \ respective parts from the caches to fill `cos_output` and `sin_output`. It uses\
    \ logical indexing based on the length of total sequences and caches specified\
    \ by `HIDDEN_DIM`, `N_ELEMENTS`, and `BLOCK_SIZE`.\n\n            - `decoding_cache_kernel`:\
    \ Targeted at decoding cache data based on sequence lengths, this kernel takes\
    \ in parameters like `cos_cache`, `sin_cache`, and `lengths`, alongside output\
    \ buffers `cos_output` and `sin_output`. It retrieves the previous cache entries\
    \ for a given sequence using its length-1 value to index into the cache, ensuring\
    \ data continuity. Important constants here include `HIDDEN_DIM`, `NUM_SEQS`,\
    \ and `BLOCK_SIZE`.\n\n            The utility function `get_xine_cache` determines\
    \ which kernel to execute based on the `is_prompts` flag, setting up computational\
    \ grids and preparing tensors for output storage. For prompt processing, it aggregates\
    \ sequence lengths to derive `total_length` and employs the `prefill_cache_kernel`.\
    \ In non-prompt scenarios, it computes indices directly from `lengths` and engages\
    \ the `decoding_cache_kernel`. This setup ensures flexible handling of cache operations\
    \ across varied sequence lengths and types.\n            \nThe test code is:\n\
    \n\ndef test_get_xine_cache():\n    # \u6D4B\u8BD5\u53C2\u6570\n    num_seqs =\
    \ 8            # \u5E8F\u5217\u6570\u91CF\n    seq_len = 10            # \u6BCF\
    \u4E2A\u5E8F\u5217\u7684\u957F\u5EA6\n    hidden_dim = 64         # \u9690\u85CF\
    \u5C42\u7EF4\u5EA6\n    max_length = 20         # \u6700\u5927\u5E8F\u5217\u957F\
    \u5EA6\n    is_prompts_list = [True, False]\n\n    # \u521B\u5EFA\u8F93\u5165\u5F20\
    \u91CF\n    lengths = torch.randint(1, max_length, (num_seqs,), dtype=torch.int32,\
    \ device='cuda')\n    cos_cache = torch.randn((max_length, hidden_dim), dtype=torch.float32,\
    \ device='cuda')\n    sin_cache = torch.randn((max_length, hidden_dim), dtype=torch.float32,\
    \ device='cuda')\n\n    results = {}\n    \n    for i, is_prompts in enumerate(is_prompts_list,\
    \ start=1):\n        cos_output, sin_output = get_xine_cache(lengths, cos_cache,\
    \ sin_cache, is_prompts=is_prompts)\n        results[f\"test_case_{i}\"] = (cos_output.shape,\
    \ sin_output.shape)\n\n    return results\n\nresult_gold = test_get_xine_cache()\n\
    \n\nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py cache_transform_triton.py\
    \ {kernel_path}` to check the correctness and performance.The kernel_path is where\
    \ you stored the generated code.\nCall Status means whether the code can be executed,\
    \ Exec Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- cache_transform_triton
