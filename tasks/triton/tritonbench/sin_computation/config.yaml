compile_command:
- python sin_computation.py
correctness_command:
- python sin_computation_perf.py
performance_command:
- tb_eval -f sin_computation.py -o sin_computation_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton kernel sin_kernel computes the element-wise sine of a\
    \ 1D input array. It takes the following parameters: in_ptr0, a pointer to the\
    \ input data; out_ptr, a pointer to the output data; n_elements, the total number\
    \ of elements to process; and BLOCK_SIZE, a compile-time constant determining\
    \ the block of data processed per program instance. The kernel uses tl.program_id(axis=0)\
    \ to identify which block it is processing and calculates offsets within the data\
    \ based on the block ID and BLOCK_SIZE. It loads input data using tl.load with\
    \ masking to prevent out-of-bounds access. After applying tl.sin to compute the\
    \ sine of each loaded element, it stores the result back into memory using tl.store,\
    \ again using a mask to ensure only valid memory locations are written. The wrapper\
    \ function sin_triton initializes the computation by determining the number of\
    \ elements in the input tensor x, and invokes the sin_kernel, specifying the grid\
    \ size as the number of elements and setting the BLOCK_SIZE to 4.\n          \
    \  \nThe test code is:\n\n\ndef test_sin_triton():\n    results = {}\n    \n \
    \   # Test case 1\n    x1 = torch.tensor([0.0, 1.0, 2.0, 3.0], device='cuda')\n\
    \    out1 = torch.empty_like(x1)\n    sin_triton(x1, out1)\n    results['test_case_1']\
    \ = out1\n\n    # Test case 2\n    x2 = torch.tensor([4.0, 5.0, 6.0, 7.0], device='cuda')\n\
    \    out2 = torch.empty_like(x2)\n    sin_triton(x2, out2)\n    results['test_case_2']\
    \ = out2\n\n    # Test case 3\n    x3 = torch.tensor([8.0, 9.0, 10.0, 11.0], device='cuda')\n\
    \    out3 = torch.empty_like(x3)\n    sin_triton(x3, out3)\n    results['test_case_3']\
    \ = out3\n\n    # Test case 4\n    x4 = torch.tensor([12.0, 13.0, 14.0, 15.0],\
    \ device='cuda')\n    out4 = torch.empty_like(x4)\n    sin_triton(x4, out4)\n\
    \    results['test_case_4'] = out4\n\n    return results\n\nresult_gold = test_sin_triton()\n\
    \n\nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py sin_computation.py {kernel_path}`\
    \ to check the correctness and performance.The kernel_path is where you stored\
    \ the generated code.\nCall Status means whether the code can be executed, Exec\
    \ Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- sin_computation
