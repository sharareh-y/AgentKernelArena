compile_command:
- python destindex_copy.py
correctness_command:
- python destindex_copy_perf.py
performance_command:
- tb_eval -f destindex_copy.py -o destindex_copy_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The provided code defines a Triton kernel, `_fwd_kernel_destindex_copy_kv`,\
    \ which is intended for copying elements from the source tensors `KV_nope` and\
    \ `KV_rope` to the destination tensors `O_nope` and `O_rope` using indices specified\
    \ in the tensor `DestLoc`. This kernel iterates over each index in the sequence,\
    \ as specified by `DestLoc`, to load elements from the `KV_nope` and `KV_rope`\
    \ tensors and subsequently store them in the corresponding position in the `O_nope`\
    \ and `O_rope` tensors based on `DestLoc`. \n\n            The kernel uses Triton's\
    \ parallel programming constructs, with `tl.load` and `tl.store` operations, ensuring\
    \ efficient memory transactions. Specifically, `tl.arange` is used to compute\
    \ offsets for batch processing of dimensions defined by `BLOCK_DMODEL_NOPE` and\
    \ `BLOCK_DMODEL_ROPE`, which represent the aligned head dimensions (to the next\
    \ power of two for optimal performance). The kernel is invoked via the `destindex_copy_kv`\
    \ function, a no-gradient context wrapper that configures grid size and execution\
    \ parameters such as `num_warps` and `num_stages` for optimal performance on the\
    \ Triton platform. \n\n            The inputs to `destindex_copy_kv` include:\n\
    \            - `KV_nope`, `KV_rope`: Source tensors of shape `(batch_size, num_heads,\
    \ head_dim)` which contain the data to be copied.\n            - `DestLoc`: A\
    \ tensor indicating the destination indices in the output tensors.\n         \
    \   - `O_nope`, `O_rope`: Output tensors which receive the copied data.\n\n  \
    \          The function checks that the shapes of corresponding source and destination\
    \ tensors match, prepares the aligned dimensions for kernel execution, calculates\
    \ strides, and invokes the kernel with these parameters. This setup supports parallel\
    \ data transfer leveraging Triton's capabilities for handling multi-dimensional\
    \ tensor operations efficiently.\n            \nThe test code is:\n\n\nimport\
    \ torch\n\ndef test_destindex_copy_kv():\n    B, N_CTX, H, H1, D, D1 = 32, 1024,\
    \ 12, 1, 128, 64\n    results = {}\n\n    # Test case\n    KV_nope = torch.randn((B\
    \ * N_CTX, H, D), dtype=torch.float16).cuda()\n    KV_rope = torch.randn((B *\
    \ N_CTX, H1, D1), dtype=torch.float16).cuda()\n    dest_loc = torch.arange(0,\
    \ B * N_CTX, dtype=torch.int32, device=\"cuda\")\n    O_nope = torch.randn((B\
    \ * N_CTX, H, D), dtype=torch.float16).cuda()\n    O_rope = torch.randn((B * N_CTX,\
    \ H1, D1), dtype=torch.float16).cuda()\n\n    destindex_copy_kv(KV_nope, KV_rope,\
    \ dest_loc, O_nope, O_rope)\n    results['test_case'] = (O_nope.clone(), O_rope.clone())\n\
    \n    return results\n\nresult_gold = test_destindex_copy_kv()\n\nDon't append\
    \ test code to the kernel code or edit test function.\n\nThe generated code should\
    \ be written into a python file.\nIf you have already created a file and wrote\
    \ the code into it, edit the code directly in the file.\nTest the code by running\
    \ `python python_bindings/tritonbench.py destindex_copy.py {kernel_path}` to check\
    \ the correctness and performance.The kernel_path is where you stored the generated\
    \ code.\nCall Status means whether the code can be executed, Exec Status means\
    \ whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- destindex_copy
