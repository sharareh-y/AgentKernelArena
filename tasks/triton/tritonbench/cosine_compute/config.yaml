compile_command:
- python cosine_compute.py
correctness_command:
- python cosine_compute_perf.py
performance_command:
- tb_eval -f cosine_compute.py -o cosine_compute_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            This Triton kernel `cos_func` is designed to compute the cosine of\
    \ each element in an input tensor `a` and write the results to an output tensor\
    \ `b`. \n            It uses a configurable constant `BLOCK_SIZE` which dictates\
    \ the number of elements each parallel thread block processes. The `offset` variable\
    \ is calculated to give each block its starting point by considering the global\
    \ program id and the thread's local position in the block using `tl.arange`. \n\
    \            The `mask` variable is created to ensure calculations are only performed\
    \ on valid tensor elements within bounds. \n            The elements from `a`\
    \ are loaded into `a_value` using `tl.load`, respecting the bounds defined by\
    \ `mask`. \n            The cosine of each element is computed with `tl.cos` and\
    \ stored in the `b_value` tensor. Finally, results are written to the output tensor\
    \ `b` using `tl.store`, again with the `mask` ensuring correct boundaries. \n\
    \            The `cos` function in Python acts as a driver for the Triton kernel,\
    \ preparing the input and output tensors, calculating the block size as the nearest\
    \ power of 2 greater than the square root of the number of elements, and determining\
    \ the grid size to cover all elements. It then executes the kernel with these\
    \ parameters.\n            \nThe test code is:\n\n\ndef test_cos_function():\n\
    \    # Create test cases with various input sizes\n    test_cases = {\n      \
    \  'test_case_1': torch.rand(1024, device='cuda') * 2 * math.pi,\n        'test_case_2':\
    \ torch.rand(2048, device='cuda') * 2 * math.pi,\n        'test_case_3': torch.rand(4096,\
    \ device='cuda') * 2 * math.pi,\n        'test_case_4': torch.rand(8192, device='cuda')\
    \ * 2 * math.pi\n    }\n    \n    results = {}\n    \n    for case_name, input_tensor\
    \ in test_cases.items():\n        # Compute cosine using Triton\n        B_triton\
    \ = cos(input_tensor)\n        results[case_name] = B_triton\n    \n    return\
    \ results\n\n# Run the test\nresult_gold = test_cos_function()\n\n\nDon't append\
    \ test code to the kernel code or edit test function.\n\nThe generated code should\
    \ be written into a python file.\nIf you have already created a file and wrote\
    \ the code into it, edit the code directly in the file.\nTest the code by running\
    \ `python python_bindings/tritonbench.py cosine_compute.py {kernel_path}` to check\
    \ the correctness and performance.The kernel_path is where you stored the generated\
    \ code.\nCall Status means whether the code can be executed, Exec Status means\
    \ whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- cosine_compute
