compile_command:
- python chunk_delta_fwd.py
correctness_command:
- python chunk_delta_fwd_perf.py
performance_command:
- tb_eval -f chunk_delta_fwd.py -o chunk_delta_fwd_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \    The Triton kernel `chunk_delta_rule_fwd_kernel_h` is a high-performance function\
    \ aimed at batch processing of input tensors `k`, `v`, and `d`, producing an output\
    \ tensor `v_new` with optional state management using `initial_state` and `final_state`.\
    \ The kernel is decorated with `triton.autotune`, which provides multiple configurations\
    \ varying the number of warps (1, 2, 4, 8, 16, 32) to identify the most efficient\
    \ execution strategy based on input sizes (`BT`, `BK`, `BV`).\n\n    The kernel\
    \ operates on a grid of blocks, each identified by `i_k`, `i_v`, and `i_bh` through\
    \ `tl.program_id`. Each block processes a portion of the input data defined by\
    \ dimensions (`K`, `V`) and manages state updates. The use of Triton's block pointers\
    \ via `tl.make_block_ptr` allows efficient memory operations by precisely controlling\
    \ the access pattern to input/output tensors within each block.\n\n    Key operations\
    \ in the kernel involve:\n    - Loading initial state (`b_h`) if `USE_INITIAL_STATE`\
    \ is true.\n    - Iterating over time dimension (`NT`) and performing block-wise\
    \ operations, including storing current state to `h`, and updating `v` using `d`\
    \ and `k`.\n    - Computing cumulative sums (`b_h_cumsum`) of the result of matrix\
    \ multiplications using `tl.dot` without TensorFloat32 to ensure precision.\n\
    \    - Storing the final cumulative state if `STORE_FINAL_STATE` is true.\n\n\
    \    The wrapper function `chunk_fwd_h_fn` sets up the computation environment\
    \ by computing block sizes based on input tensor dimensions (`BT`, `BK`, `BV`)\
    \ and constraints like maximum warp size. It initializes the output tensors `h`\
    \ and `v_new`, configures the execution grid, and calls the Triton kernel with\
    \ appropriate parameters, including strides calculated from input tensor shapes.\n\
    \n    Overall, the provided Triton code is optimized for GPU execution, leveraging\
    \ Triton's features like configurable warps and block pointers to maximize throughput\
    \ while maintaining precision. The focus is on efficient use of memory and parallelism\
    \ to handle large-scale tensor operations typical in deep learning workloads.\n\
    \    \nThe test code is:\n\n\nimport torch\n\n# Test function for chunk_fwd_h_fn\n\
    def test_chunk_fwd_h_fn():\n    B, H, T, K, V = 2, 4, 128, 64, 64  # Example dimensions\n\
    \    BT = 32  # Block size for T dimension\n\n    k = torch.randn(B, H, K, T,\
    \ dtype=torch.float32, device='cuda')\n    w = torch.randn(B, H, T, K, dtype=torch.float32,\
    \ device='cuda')\n    u = torch.randn(B, H, T, V, dtype=torch.float32, device='cuda')\n\
    \n    results = {}\n\n    # Test without initial and final states\n    h, v_new\
    \ = chunk_fwd_h_fn(k, w, u, BT, initial_state=None, final_state=None)\n    results['test_case_1']\
    \ = (h.shape, v_new.shape)\n\n    # Test with initial and final states\n    initial_state\
    \ = torch.zeros(B, H, K, V, dtype=torch.float32, device='cuda')\n    final_state\
    \ = torch.zeros(B, H, K, V, dtype=torch.float32, device='cuda')\n    h, v_new\
    \ = chunk_fwd_h_fn(k, w, u, BT, initial_state=initial_state, final_state=final_state)\n\
    \    results['test_case_2'] = (h.shape, v_new.shape)\n\n    return results\n\n\
    # Run tests\nresult_gold = test_chunk_fwd_h_fn()\n\n\nDon't append test code to\
    \ the kernel code or edit test function.\n\nThe generated code should be written\
    \ into a python file.\nIf you have already created a file and wrote the code into\
    \ it, edit the code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ chunk_delta_fwd.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- chunk_delta_fwd
