compile_command:
- python triton_argmax.py
correctness_command:
- python triton_argmax_perf.py
performance_command:
- tb_eval -f triton_argmax.py -o triton_argmax_output.json -run_on_code -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \        This code implements a GPU-based argmax operation using Triton to optimize\
    \ performance for different tensor shapes and dimensionalities. \n\n        The\
    \ primary function, `argmax`, executes one of two pathways based on whether a\
    \ specific dimension is specified. Without a dimension (`dim=None`), it treats\
    \ the input tensor as a flat array, applying a two-stage reduction:\n        \n\
    \        - `argmax_kernel_1`: This kernel iterates over blocks of the input tensor,\
    \ calculating the maximum value and its corresponding index within each block.\
    \ The kernel parameters include:\n          - `inp`: The input tensor.\n     \
    \     - `mid_value`, `mid_index`: Buffers to store intermediate max values and\
    \ their indices.\n          - `M`: Total number of elements.\n          - `BLOCK_SIZE`:\
    \ Defines the block of elements each instance processes.\n          - `INT64_INDEX`:\
    \ Flags whether indices require 64-bit representation based on input size.\n \
    \       \n        - `argmax_kernel_2`: This kernel finalizes the maximum index\
    \ from the intermediate results. It reads from `mid_value` and `mid_index` to\
    \ determine the overall maximum index and store it in the output.\n          -\
    \ `mid_value`, `mid_index`: Intermediate results from the first kernel.\n    \
    \      - `out`: The tensor where the final maximum index is stored.\n        \
    \  - `mid_size`: The number of blocks processed.\n          - `BLOCK_MID`: Defines\
    \ the intermediate block size for reduction.\n        \n        When a dimension\
    \ is specified, the `argmax_kernel` is employed, which operates as follows:\n\
    \        - Iterates over the specified dimension to find the maximum value index\
    \ across rows/columns.\n        - `M`, `N`, `K`: Represent the product of dimensions\
    \ before, along, and after the specified dimension.\n        - `BLOCK_M`, `BLOCK_N`:\
    \ Define the number of elements each block of threads should process in these\
    \ dimensions.\n        \n        The function ensures correct memory use with\
    \ either int32 or int64 indices based on the tensor's total number of elements\
    \ by calling `can_use_int32_index`. It adjusts the execution grid dynamically\
    \ to accommodate tensor size and block configuration.\n    \nThe test code is:\n\
    \n\nimport torch\n\ndef test_argmax():\n    results = {}\n\n    # Test case 1:\
    \ 1D input tensor\n    inp = torch.randn(1024, device='cuda')\n    results['test_case_1']\
    \ = argmax(inp)\n\n    # Test case 2: 2D input tensor, dim=0\n    inp = torch.randn(1024,\
    \ 1024, device='cuda')\n    results['test_case_2'] = argmax(inp, dim=0)\n\n  \
    \  # Test case 3: 2D input tensor, dim=1\n    inp = torch.randn(1024, 1024, device='cuda')\n\
    \    results['test_case_3'] = argmax(inp, dim=1)\n\n    # Test case 4: 3D input\
    \ tensor\n    inp = torch.randn(64, 128, 256, device='cuda')\n    results['test_case_4']\
    \ = argmax(inp, dim=2)\n\n    return results\n\n# Run the test\nresult_gold =\
    \ test_argmax()\n\n\nDon't append test code to the kernel code or edit test function.\n\
    \nThe generated code should be written into a python file.\nIf you have already\
    \ created a file and wrote the code into it, edit the code directly in the file.\n\
    Test the code by running `python python_bindings/tritonbench.py triton_argmax.py\
    \ {kernel_path}` to check the correctness and performance.The kernel_path is where\
    \ you stored the generated code.\nCall Status means whether the code can be executed,\
    \ Exec Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- triton_argmax
