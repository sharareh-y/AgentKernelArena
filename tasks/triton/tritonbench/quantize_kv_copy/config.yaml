compile_command:
- python quantize_kv_copy.py
correctness_command:
- python quantize_kv_copy_perf.py
performance_command:
- tb_eval -f quantize_kv_copy.py -o quantize_kv_copy_output.json -run_on_code -ds
  tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    \            The Triton kernel `_fwd_kernel_destindex_copy_quantize_kv` is designed\
    \ for quantizing and copying key-value (KV) tensor data using specified destination\
    \ indices. It processes a tensor `K` where each element is accessed using calculated\
    \ offsets and destination indices from `Dest_loc`. The main operations include:\n\
    \            1. Loading source data from tensor `K` for a specific group and dimension.\n\
    \            2. Computing the absolute maximum values within each group to determine\
    \ scaling factors needed to normalize the data to fit into int8 format.\n    \
    \        3. Quantizing the data by dividing each element by its group's scaling\
    \ factor and casting it to int8.\n            4. Storing quantized data to the\
    \ `Out` tensor at positions specified by `dest_index` derived from `Dest_loc`.\n\
    \            5. Saving the scaling factors into the `Out_scale` tensor for later\
    \ dequantization.\n\n            The `destindex_copy_quantize_kv` function acts\
    \ as a higher-level interface for this kernel, handling input reshaping and invoking\
    \ the kernel. It sets up the grid size based on sequence length and head count,\
    \ ensures that the head dimension is divisible by the quantization group dimension,\
    \ and calls the kernel with the correct parameters. The head dimension is divided\
    \ into groups for more efficient processing.\n\n            Key parameters and\
    \ functions used:\n            - `K`: Source tensor of shape (batch, head, head_dim).\n\
    \            - `DestLoc`: Destination indices tensor indicating where each sequence\
    \ element's output should be written.\n            - `Out`: Output tensor to store\
    \ quantized data.\n            - `Out_scale`: Tensor to store scaling factors\
    \ for each group.\n            - `group_size`, `BLOCK_GROUP_NUM`, `BLOCK_GROUP_DIM`:\
    \ Parameters defining the size and dimensions of groups used in quantization.\n\
    \            - `tl.load`, `tl.store`: Triton operations to load from and store\
    \ into GPU memory.\n            \nThe test code is:\n\n\nimport torch\nimport\
    \ triton\nimport triton.language as tl\n\n@triton.jit\ndef _fwd_kernel_destindex_copy_quantize_kv(\n\
    \    K,\n    Dest_loc,\n    Out,\n    Out_scale,\n    stride_k_bs,\n    stride_k_h,\n\
    \    stride_k_g,\n    stride_k_d,\n    stride_o_bs,\n    stride_o_h,\n    stride_o_g,\n\
    \    stride_o_d,\n    stride_os_bs,\n    stride_os_h,\n    stride_os_g,\n    group_size,\n\
    \    BLOCK_GROUP_NUM: tl.constexpr,\n    BLOCK_GROUP_DIM: tl.constexpr,\n):\n\
    \    cur_index = tl.program_id(0)\n    cur_head = tl.program_id(1)\n\n    offs_g\
    \ = tl.arange(0, BLOCK_GROUP_NUM)\n    offs_d = tl.arange(0, BLOCK_GROUP_DIM)\n\
    \n    dest_index = tl.load(Dest_loc + cur_index)\n\n    src_data = tl.load(\n\
    \        K + cur_index * stride_k_bs + cur_head * stride_k_h + offs_g[:, None]\
    \ * stride_k_g + offs_d[None, :],\n        mask=offs_g[:, None] < group_size,\n\
    \        other=0.0,\n    )\n    abs_data = tl.abs(src_data)\n    data_scale =\
    \ (tl.max(abs_data, axis=1) / 127.0).to(Out_scale.dtype.element_ty)\n    q_src_data\
    \ = (src_data / data_scale[:, None]).to(tl.int8)\n\n    o_ptrs = Out + dest_index\
    \ * stride_o_bs + cur_head * stride_o_h + offs_g[:, None] * stride_o_g + offs_d[None,\
    \ :]\n    os_ptrs = Out_scale + dest_index * stride_os_bs + cur_head * stride_os_h\
    \ + offs_g\n    tl.store(o_ptrs, q_src_data, mask=offs_g[:, None] < group_size)\n\
    \    tl.store(os_ptrs, data_scale, mask=offs_g < group_size)\n    return\n\n\n\
    @torch.no_grad()\ndef destindex_copy_quantize_kv(K, DestLoc, Out, Out_scale):\n\
    \    seq_len = DestLoc.shape[0]\n    head_num = K.shape[1]\n    head_dim = K.shape[2]\n\
    \    quant_group_dim = 8\n\n    assert head_dim % quant_group_dim == 0, \"error\
    \ head dim, can not been supported to copy quant kv\"\n    grid = (seq_len, head_num)\n\
    \    num_warps = 1\n\n    group_size = head_dim // quant_group_dim\n    group_dim\
    \ = quant_group_dim\n\n    K = K.view((K.shape[0], K.shape[1], group_size, group_dim))\n\
    \    Out = Out.view(Out.shape[0], Out.shape[1], group_size, group_dim)\n\n   \
    \ _fwd_kernel_destindex_copy_quantize_kv[grid](\n        K,\n        DestLoc,\n\
    \        Out,\n        Out_scale,\n        K.stride(0),\n        K.stride(1),\n\
    \        K.stride(2),\n        K.stride(3),\n        Out.stride(0),\n        Out.stride(1),\n\
    \        Out.stride(2),\n        Out.stride(3),\n        Out_scale.stride(0),\n\
    \        Out_scale.stride(1),\n        Out_scale.stride(2),\n        group_size,\n\
    \        BLOCK_GROUP_NUM=triton.next_power_of_2(group_size),\n        BLOCK_GROUP_DIM=group_dim,\n\
    \        num_warps=num_warps,\n        num_stages=1,\n    )\n    return\n\n\n\
    #######################################################################################################\n\
    \n\nimport torch\n\ndef test_destindex_copy_quantize_kv():\n    # Define the input\
    \ tensors\n    batch_size = 2\n    head_num = 4\n    head_dim = 16\n    seq_len\
    \ = 10\n    quant_group_dim = 8\n\n    # Ensure head_dim is divisible by quant_group_dim\n\
    \    assert head_dim % quant_group_dim == 0\n\n    # Create random input tensors\n\
    \    K = torch.randn((seq_len, head_num, head_dim), dtype=torch.float32, device='cuda')\n\
    \    DestLoc = torch.randint(0, seq_len, (seq_len,), dtype=torch.int32, device='cuda')\n\
    \    Out = torch.empty_like(K, dtype=torch.int8)\n    Out_scale = torch.empty((seq_len,\
    \ head_num, head_dim // quant_group_dim), dtype=torch.float32, device='cuda')\n\
    \n    # Case 1: Normal execution (no early exit conditions)\n    destindex_copy_quantize_kv(K,\
    \ DestLoc, Out, Out_scale)\n    result_case_1 = {\n        \"Out\": Out,\n   \
    \     \"Out_scale\": Out_scale\n    }\n\n    # Case 2: Handle a small batch size,\
    \ less than group_size\n    batch_size_small = 1\n    K_small = torch.randn((batch_size_small,\
    \ head_num, head_dim), dtype=torch.float32, device='cuda')\n    DestLoc_small\
    \ = torch.randint(0, seq_len, (batch_size_small,), dtype=torch.int32, device='cuda')\n\
    \    Out_small = torch.empty_like(K_small, dtype=torch.int8)\n    Out_scale_small\
    \ = torch.empty((batch_size_small, head_num, head_dim // quant_group_dim), dtype=torch.float32,\
    \ device='cuda')\n\n    destindex_copy_quantize_kv(K_small, DestLoc_small, Out_small,\
    \ Out_scale_small)\n    result_case_2 = {\n        \"Out\": Out_small,\n     \
    \   \"Out_scale\": Out_scale_small\n    }\n\n    # Case 3: Modify DestLoc to contain\
    \ different sequence lengths\n    DestLoc_varied = torch.randint(0, seq_len, (seq_len\
    \ // 2,), dtype=torch.int32, device='cuda')\n    Out_varied = torch.empty_like(K,\
    \ dtype=torch.int8)\n    Out_scale_varied = torch.empty((seq_len // 2, head_num,\
    \ head_dim // quant_group_dim), dtype=torch.float32, device='cuda')\n\n    destindex_copy_quantize_kv(K,\
    \ DestLoc_varied, Out_varied, Out_scale_varied)\n    result_case_3 = {\n     \
    \   \"Out\": Out_varied,\n        \"Out_scale\": Out_scale_varied\n    }\n\n \
    \   # Case 4: Head dimension not divisible by quant_group_dim (assert will trigger)\n\
    \    try:\n        head_dim_invalid = 15  # Invalid head_dim\n        K_invalid\
    \ = torch.randn((seq_len, head_num, head_dim_invalid), dtype=torch.float32, device='cuda')\n\
    \        DestLoc_invalid = torch.randint(0, seq_len, (seq_len,), dtype=torch.int32,\
    \ device='cuda')\n        Out_invalid = torch.empty_like(K_invalid, dtype=torch.int8)\n\
    \        Out_scale_invalid = torch.empty((seq_len, head_num, head_dim_invalid\
    \ // quant_group_dim), dtype=torch.float32, device='cuda')\n\n        destindex_copy_quantize_kv(K_invalid,\
    \ DestLoc_invalid, Out_invalid, Out_scale_invalid)\n    except AssertionError\
    \ as e:\n        result_case_4 = str(e)\n\n    return {\n        \"result_case_1\"\
    : result_case_1,\n        \"result_case_2\": result_case_2,\n        \"result_case_3\"\
    : result_case_3,\n        \"result_case_4\": result_case_4,\n    }\n\nresult_gold\
    \ = test_destindex_copy_quantize_kv()\n\n\nDon't append test code to the kernel\
    \ code or edit test function.\n\nThe generated code should be written into a python\
    \ file.\nIf you have already created a file and wrote the code into it, edit the\
    \ code directly in the file.\nTest the code by running `python python_bindings/tritonbench.py\
    \ quantize_kv_copy.py {kernel_path}` to check the correctness and performance.The\
    \ kernel_path is where you stored the generated code.\nCall Status means whether\
    \ the code can be executed, Exec Status means whether the code is functionally\
    \ correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- quantize_kv_copy
