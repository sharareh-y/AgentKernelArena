compile_command:
- python vector_addition_custom.py
correctness_command:
- python vector_addition_custom_perf.py
performance_command:
- tb_eval -f vector_addition_custom.py -o vector_addition_custom_output.json -run_on_code
  -ds tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    The code involves a custom addition operation utilizing the Triton programming\
    \ model to perform element-wise addition on two input PyTorch tensors, `a` and\
    \ `b`. The key components are the Triton kernel `_add_kernel` and its wrapper\
    \ function `custom_add`.\n\nFunction `_add_kernel(A, B, C, size, BLOCK)`:\n- This\
    \ Triton kernel function, decorated with `@triton.jit`, signifies its use of just-in-time\
    \ compilation.\n- Parameters:\n  - `A`, `B`: Pointers to input tensors containing\
    \ the data to be added.\n  - `C`: Pointer to the output tensor where the result\
    \ will be stored.\n  - `size`: Scalar specifying the number of elements in the\
    \ tensors.\n  - `BLOCK`: A compile-time constant defining the number of elements\
    \ each program instance processes concurrently.\n- The kernel computes the addition\
    \ of `A` and `B` and stores the result in `C`.\n- Program index for parallel execution\
    \ is fetched via `tl.program_id(0)`.\n- `offs` calculates the offsets for block-wise\
    \ data processing, determined by `prog_id * BLOCK + tl.arange(0, BLOCK)`.\n- Loads\
    \ data from `A` and `B` using `tl.load` with masks to prevent out-of-bound access\
    \ using `offs < size`.\n- The resulting sum is stored in `C` with `tl.store` under\
    \ the same mask condition to handle edge cases.\n\nFunction `custom_add(a, b)`:\n\
    - Acts as a wrapper to invoke `_add_kernel` and handle tensor operations within\
    \ the PyTorch framework.\n- Initializes `c`, an empty tensor with the same shape\
    \ as `a`, to store the result of the addition.\n- Computes `size` of input tensors\
    \ which dictates the operation range.\n- Sets `BLOCK` size to 16, defining the\
    \ granularity of each program instance's data processing.\n- Calculates `grid`\
    \ using `triton.cdiv(size, BLOCK)` to determine the number of program instances\
    \ required, ensuring complete coverage of the tensor.\n- Launches `_add_kernel`\
    \ with calculated `grid`, and provides tensor pointers and necessary arguments\
    \ for execution.\n- The resultant tensor `c` is returned after kernel execution.\n\
    \nThis implementation splits the workload into blocks, processed in parallel,\
    \ handling edge cases with masks. The consistent BLOCK size ensures efficient\
    \ memory access patterns.\n\nThe test code is:\n\n\nimport torch\n\ndef test_add():\n\
    \    # \u6D4B\u8BD5\u7528\u4F8B 1\uFF1A\u7B80\u5355\u7684\u4E24\u4E2A\u5411\u91CF\
    \u52A0\u6CD5\n    a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\
    \ 14, 15, 16], dtype=torch.float32, device='cuda')\n    b = torch.tensor([16,\
    \ 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1], dtype=torch.float32, device='cuda')\n\
    \    c = custom_add(a, b)\n    test_results = {\n        \"test_case_1\": c,\n\
    \    }\n    # \u6D4B\u8BD5\u7528\u4F8B 2\uFF1A\u4E0D\u540C\u503C\u7684\u52A0\u6CD5\
    \n    a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32, device='cuda')\n\
    \    b = torch.tensor([8, 7, 6, 5, 4, 3, 2, 1], dtype=torch.float32, device='cuda')\n\
    \    c = custom_add(a, b)\n    test_results[\"test_case_2\"] = c\n    # \u6D4B\
    \u8BD5\u7528\u4F8B 3\uFF1A\u66F4\u5927\u5411\u91CF\u7684\u52A0\u6CD5\n    a =\
    \ torch.arange(32, dtype=torch.float32, device='cuda')\n    b = torch.arange(32,\
    \ 0, -1, dtype=torch.float32, device='cuda')\n    c = custom_add(a, b)\n    test_results[\"\
    test_case_3\"] = c\n    # \u6D4B\u8BD5\u7528\u4F8B 4\uFF1A\u7A7A\u5411\u91CF\u7684\
    \u8FB9\u754C\u60C5\u51B5\n    a = torch.tensor([], dtype=torch.float32, device='cuda')\n\
    \    b = torch.tensor([], dtype=torch.float32, device='cuda')\n    c = custom_add(a,\
    \ b)\n    test_results[\"test_case_4\"] = c\n    # test_results = {\n    #   \
    \  \"test_case_1\": custom_add(a, b),\n    #     \"test_case_2\": custom_add(a,\
    \ b),\n    #     \"test_case_3\": custom_add(a, b),\n    #     \"test_case_4\"\
    : custom_add(a, b),\n    # }\n    return test_results\n\nresult_gold = test_add()\n\
    \nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py vector_addition_custom.py\
    \ {kernel_path}` to check the correctness and performance.The kernel_path is where\
    \ you stored the generated code.\nCall Status means whether the code can be executed,\
    \ Exec Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- vector_addition_custom
