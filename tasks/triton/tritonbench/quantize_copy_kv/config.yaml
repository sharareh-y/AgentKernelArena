compile_command:
- python quantize_copy_kv.py
correctness_command:
- python quantize_copy_kv_perf.py
performance_command:
- tb_eval -f quantize_copy_kv.py -o quantize_copy_kv_output.json -run_on_code -ds
  tbg
task_type: instruction2triton
task_result_template: null
prompt:
  cheatsheet: null
  instructions: "You are a expert in writing Triton operators for efficient GPU programming.\
    \ Use triton language write a kernel and wrapper according following instruction.\n\
    The code defines a Triton kernel `_fwd_kernel_destindex_copy_quantize_kv` and\
    \ a Python wrapper function `destindex_copy_quantize_kv`. The kernel processes\
    \ the input tensor `K` by loading it according to the block size specified by\
    \ `BLOCK_DMODEL` and `BLOCK_HEAD`. The function operates across multiple heads\
    \ as specified by `head_num`. The kernel uses the `DestLoc` array to determine\
    \ the destination index where each sequence element should be copied to in the\
    \ output tensor `Out`. It calculates the absolute maximum for each head slice\
    \ to determine a scaling factor, which is then used to quantize the data to int8.\
    \ This quantized data is stored in `Out`, and the scaling factors are stored in\
    \ `Out_scale`. The kernel uses 1 warp, and the grid size is determined by the\
    \ sequence length of `DestLoc`. The function assumes `K`, `Out`, and `Out_scale`\
    \ have consistent dimensions for heads and the model. The wrapper function sets\
    \ up this operation by defining grid and block sizes, strides, and invoking the\
    \ kernel.\n\nThe test code is:\n\n\ndef test_destindex_copy_quantize_kv():\n \
    \   B, N_CTX, H, D = 16, 512, 8, 64\n    \n    # Test case 1\n    src1 = torch.randn((B\
    \ * N_CTX, H, D), dtype=torch.float16).cuda()\n    dest_loc1 = torch.arange(0,\
    \ B * N_CTX, dtype=torch.int32).cuda()\n    value_dest1 = torch.randn((B * N_CTX,\
    \ H, D), dtype=torch.float16).cuda().to(torch.int8)\n    scale_dest1 = torch.randn((B\
    \ * N_CTX, H, 1), dtype=torch.float16).cuda()\n    destindex_copy_quantize_kv(src1,\
    \ dest_loc1, value_dest1, scale_dest1)\n\n    # Test case 2 - Randomized location\
    \ indices\n    dest_loc2 = torch.randint(0, B * N_CTX, (B * N_CTX,), dtype=torch.int32).cuda()\n\
    \    src2 = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda()\n    value_dest2\
    \ = torch.randn((B * N_CTX, H, D), dtype=torch.float16).cuda().to(torch.int8)\n\
    \    scale_dest2 = torch.randn((B * N_CTX, H, 1), dtype=torch.float16).cuda()\n\
    \    destindex_copy_quantize_kv(src2, dest_loc2, value_dest2, scale_dest2)\n\n\
    \    # Test case 4 - Larger head dimension\n    D4 = 256\n    src3 = torch.randn((B\
    \ * N_CTX, H, D4), dtype=torch.float16).cuda()\n    dest_loc3 = torch.arange(0,\
    \ B * N_CTX, dtype=torch.int32).cuda()\n    value_dest3 = torch.randn((B * N_CTX,\
    \ H, D4), dtype=torch.float16).cuda().to(torch.int8)\n    scale_dest3 = torch.randn((B\
    \ * N_CTX, H, 1), dtype=torch.float16).cuda()\n    destindex_copy_quantize_kv(src3,\
    \ dest_loc3, value_dest3, scale_dest3)\n\n    results = {\n        \"test_case_1\"\
    : value_dest1,\n        \"test_case_2\": value_dest2,\n        \"test_case_3\"\
    : value_dest3,\n    }\n\n    return results\n\nresult_gold = test_destindex_copy_quantize_kv()\n\
    \n\nDon't append test code to the kernel code or edit test function.\n\nThe generated\
    \ code should be written into a python file.\nIf you have already created a file\
    \ and wrote the code into it, edit the code directly in the file.\nTest the code\
    \ by running `python python_bindings/tritonbench.py quantize_copy_kv.py {kernel_path}`\
    \ to check the correctness and performance.The kernel_path is where you stored\
    \ the generated code.\nCall Status means whether the code can be executed, Exec\
    \ Status means whether the code is functionally correct.\n"
  source_code: null
source_file_path:
- null
target_kernel_functions:
- quantize_copy_kv
